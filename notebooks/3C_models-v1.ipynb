{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\influence\\sample_submission.csv\n",
      "data\\influence\\solution.csv\n",
      "data\\influence\\test.csv\n",
      "data\\influence\\train.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "DATA_DIR=Path('../data/influence')\n",
    "for dirname, _, filenames in os.walk(DATA_DIR):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test.csv\"\n",
    "SOLUTION_PATH = DATA_DIR / \"solution.csv\"\n",
    "\n",
    "SUBMISSION_PATH = Path(\"../submissions/v1\")\n",
    "SUBMISSION_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "PURPOSE_LABELS = {\n",
    "    0: \"BACKGROUND\",\n",
    "    1: \"COMPARES_CONTRASTS\",\n",
    "    2: \"EXTENSION\",\n",
    "    3: \"FUTURE\",\n",
    "    4: \"MOTIVATION\",\n",
    "    5: \"USES\"\n",
    "}\n",
    "\n",
    "INFLUENCE_LABELS = {\n",
    "    0: \"INCIDENTAL\",\n",
    "    1: \"INFLUENTIAL\"\n",
    "}\n",
    "\n",
    "TASKS={\n",
    "    \"purpose\": [\"citation_class_label\", PURPOSE_LABELS],\n",
    "    \"influence\": [\"citation_influence_label\", INFLUENCE_LABELS]\n",
    "}\n",
    "\n",
    "np.random.seed(250320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'core_id', 'citing_title', 'citing_author', 'cited_title',\n",
       "       'cited_author', 'citation_context', 'citation_influence_label',\n",
       "       'citation_class_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(TRAIN_PATH).merge(\n",
    "    pd.read_csv(str(TRAIN_PATH).replace(\"influence\", \"purpose\"))[[\"unique_id\", \"citation_class_label\"]],\n",
    "    on=\"unique_id\"\n",
    ")\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'core_id', 'citing_title', 'citing_author', 'cited_title',\n",
       "       'cited_author', 'citation_context'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(TEST_PATH).merge(\n",
    "    pd.read_csv(str(TEST_PATH).replace(\"influence\", \"purpose\"))[[\"unique_id\"]],\n",
    "    on=\"unique_id\"\n",
    ")\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'citation_influence_label', 'citation_class_label'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_solution = pd.read_csv(SOLUTION_PATH).merge(\n",
    "    pd.read_csv(str(SOLUTION_PATH).replace(\"influence\", \"purpose\")),\n",
    "    on=\"unique_id\"\n",
    ")\n",
    "df_solution.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.merge(df_solution, on=\"unique_id\")\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>core_id</th>\n",
       "      <th>citing_title</th>\n",
       "      <th>citing_author</th>\n",
       "      <th>cited_title</th>\n",
       "      <th>cited_author</th>\n",
       "      <th>citation_context</th>\n",
       "      <th>citation_influence_label</th>\n",
       "      <th>citation_class_label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CC1</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Pro...</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Web search personalization with ontological us...</td>\n",
       "      <td>Sieg</td>\n",
       "      <td>They usually generate user models that describ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CC2</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Pro...</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Exploring Scholarly Data with Rexplore</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>The Computer Science Ontology (CSO)[3]is a lar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CC3</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Pro...</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Klink-2: Integrating Multiple Web Sources to G...</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>In order to do so, we characterized all SN pub...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CC4</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Pro...</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Forecasting the Spreading of Technologies in R...</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>This API supports a number of applications, in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CC5</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Pro...</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Supporting Springer Nature Editors by means of...</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>It works according to three main steps:1) It r...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id    core_id                                       citing_title  \\\n",
       "0       CC1  158977742  Ontology-Based Recommendation of Editorial Pro...   \n",
       "1       CC2  158977742  Ontology-Based Recommendation of Editorial Pro...   \n",
       "2       CC3  158977742  Ontology-Based Recommendation of Editorial Pro...   \n",
       "3       CC4  158977742  Ontology-Based Recommendation of Editorial Pro...   \n",
       "4       CC5  158977742  Ontology-Based Recommendation of Editorial Pro...   \n",
       "\n",
       "              citing_author  \\\n",
       "0  Thiviyan Thanapalasingam   \n",
       "1  Thiviyan Thanapalasingam   \n",
       "2  Thiviyan Thanapalasingam   \n",
       "3  Thiviyan Thanapalasingam   \n",
       "4  Thiviyan Thanapalasingam   \n",
       "\n",
       "                                         cited_title cited_author  \\\n",
       "0  Web search personalization with ontological us...         Sieg   \n",
       "1             Exploring Scholarly Data with Rexplore      Osborne   \n",
       "2  Klink-2: Integrating Multiple Web Sources to G...      Osborne   \n",
       "3  Forecasting the Spreading of Technologies in R...      Osborne   \n",
       "4  Supporting Springer Nature Editors by means of...      Osborne   \n",
       "\n",
       "                                    citation_context  \\\n",
       "0  They usually generate user models that describ...   \n",
       "1  The Computer Science Ontology (CSO)[3]is a lar...   \n",
       "2  In order to do so, we characterized all SN pub...   \n",
       "3  This API supports a number of applications, in...   \n",
       "4  It works according to three main steps:1) It r...   \n",
       "\n",
       "   citation_influence_label  citation_class_label  split  \n",
       "0                         0                     5  train  \n",
       "1                         0                     0  train  \n",
       "2                         0                     0  train  \n",
       "3                         1                     0  train  \n",
       "4                         1                     5  train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([\n",
    "    df_train.assign(split=\"train\"),\n",
    "    df_test.assign(split=\"test\"),\n",
    "], axis=0, sort=False).reset_index(drop=True).astype({task[0]: int for task in TASKS.values()})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    3000\n",
       "test     1000\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citation_class_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>546</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>153</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split                 test  train\n",
       "citation_class_label             \n",
       "0                      546   1648\n",
       "5                      153    475\n",
       "1                      121    368\n",
       "4                      106    276\n",
       "2                       59    171\n",
       "3                       15     62"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(\n",
    "    index=\"citation_class_label\", columns=\"split\", values=\"unique_id\", aggfunc=len\n",
    ").sort_values(\"train\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 13480)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = ColumnTransformer([\n",
    "    #(\"citing_tfidf\", TfidfVectorizer(), \"citing_title\"),\n",
    "    #(\"cited_tfidf\", TfidfVectorizer(), \"cited_title\"),\n",
    "    (\"citation_context_tfidf\", TfidfVectorizer(),\"citation_context\"),\n",
    "])\n",
    "ct.fit(df)\n",
    "df_features = ct.transform(df)\n",
    "df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['submissions\\\\v2\\\\df_features.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save transformer\n",
    "dump(ct, SUBMISSION_PATH / \"ColumnTransformer.joblib\")\n",
    "dump(df_features, SUBMISSION_PATH / \"df_features.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4000x13480 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 118873 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x13480 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 57 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features[[0, 1, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df, label_col, split=\"train\"):\n",
    "    split_idx = df[(df.split == split)].index.tolist()\n",
    "    X = df_features[split_idx]\n",
    "    y = df.iloc[split_idx][label_col]\n",
    "    print(f\"{split}: X={X.shape}, y={y.shape}\")\n",
    "    return X, y, split_idx\n",
    "\n",
    "def submission_pipeline(model, df, df_features, task, model_key=None, to_dense=False):\n",
    "    # Setup submission folder\n",
    "    submission_folder = SUBMISSION_PATH / f\"{model_key}_{task}\"\n",
    "    submission_folder.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Generated folder: {submission_folder}\")\n",
    "    \n",
    "    model_file = submission_folder / \"model.joblib\"\n",
    "    submission_file=submission_folder / f\"submission.csv\"\n",
    "    \n",
    "    label_col, label_dict = TASKS[task]\n",
    "    \n",
    "    X_train, y_train, train_idx = generate_data(df, label_col, split=\"train\")\n",
    "    X_test, y_test, test_idx = generate_data(df, label_col, split=\"test\")\n",
    "    print(f\"Training model\")\n",
    "    if to_dense:\n",
    "        X_train = X_train.toarray()\n",
    "        X_test = X_test.toarray()\n",
    "    model.fit(X_train, y_train.astype(int))\n",
    "    dump(model, model_file)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    print(\"Output label dist\")\n",
    "    print(pd.Series(y_test_pred).map(label_dict).value_counts())\n",
    "    \n",
    "    target_names = list(sorted(label_dict.values()))\n",
    "    \n",
    "    # Print reports \n",
    "    print(\"Training report\")\n",
    "    print(classification_report(y_train, y_train_pred, target_names=target_names))\n",
    "    print(\"Test report\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
    "    \n",
    "    train_report = classification_report(y_train, y_train_pred, target_names=target_names, output_dict=True)\n",
    "    test_report = classification_report(y_test, y_test_pred, target_names=target_names, output_dict=True)\n",
    "    \n",
    "    print(f\"Writing submission file: {submission_file}\")\n",
    "    df.iloc[test_idx][[\"unique_id\"]].assign(**{label_col: y_test_pred}).to_csv(submission_file, index=False)\n",
    "    return model, train_report, test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gbt\": [GradientBoostingClassifier, dict()],\n",
    "    \"rf\": [RandomForestClassifier, dict(n_jobs=-1)],\n",
    "    \"mlp-3\": [MLPClassifier, dict(hidden_layer_sizes=(256,256,128))],\n",
    "    \"mlp\": [MLPClassifier, dict()],\n",
    "    \"lr\": [LogisticRegressionCV, dict(n_jobs=-1)]\n",
    "}\n",
    "\n",
    "DENSE_MODELS = {\"mlp\", \"mlp-3\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbt [<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, {}]\n",
      "Generated folder: submissions\\v2\\gbt_purpose\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n",
      "Output label dist\n",
      "BACKGROUND            925\n",
      "USES                   28\n",
      "COMPARES_CONTRASTS     19\n",
      "EXTENSION              12\n",
      "MOTIVATION             10\n",
      "FUTURE                  6\n",
      "dtype: int64\n",
      "Training report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.70      1.00      0.82      1648\n",
      "COMPARES_CONTRASTS       0.99      0.41      0.58       368\n",
      "         EXTENSION       1.00      0.50      0.67       171\n",
      "            FUTURE       1.00      0.98      0.99        62\n",
      "        MOTIVATION       1.00      0.43      0.60       276\n",
      "              USES       0.98      0.49      0.65       475\n",
      "\n",
      "          accuracy                           0.76      3000\n",
      "         macro avg       0.95      0.64      0.72      3000\n",
      "      weighted avg       0.83      0.76      0.74      3000\n",
      "\n",
      "Test report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.54      0.92      0.68       546\n",
      "COMPARES_CONTRASTS       0.21      0.03      0.06       121\n",
      "         EXTENSION       0.17      0.03      0.06        59\n",
      "            FUTURE       0.00      0.00      0.00        15\n",
      "        MOTIVATION       0.00      0.00      0.00       106\n",
      "              USES       0.36      0.07      0.11       153\n",
      "\n",
      "          accuracy                           0.52      1000\n",
      "         macro avg       0.21      0.18      0.15      1000\n",
      "      weighted avg       0.39      0.52      0.40      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\gbt_purpose\\submission.csv\n",
      "Wall time: 36.3 s\n",
      "Generated folder: submissions\\v2\\gbt_influence\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n",
      "Output label dist\n",
      "INCIDENTAL     614\n",
      "INFLUENTIAL    386\n",
      "dtype: int64\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.74      0.88      0.80      1568\n",
      " INFLUENTIAL       0.83      0.66      0.74      1432\n",
      "\n",
      "    accuracy                           0.77      3000\n",
      "   macro avg       0.79      0.77      0.77      3000\n",
      "weighted avg       0.78      0.77      0.77      3000\n",
      "\n",
      "Test report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.50      0.67      0.57       457\n",
      " INFLUENTIAL       0.60      0.43      0.50       543\n",
      "\n",
      "    accuracy                           0.54      1000\n",
      "   macro avg       0.55      0.55      0.53      1000\n",
      "weighted avg       0.55      0.54      0.53      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\gbt_influence\\submission.csv\n",
      "Wall time: 6.63 s\n",
      "rf [<class 'sklearn.ensemble.forest.RandomForestClassifier'>, {'n_jobs': -1}]\n",
      "Generated folder: submissions\\v2\\rf_purpose\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output label dist\n",
      "BACKGROUND            951\n",
      "COMPARES_CONTRASTS     23\n",
      "USES                   20\n",
      "MOTIVATION              3\n",
      "EXTENSION               3\n",
      "dtype: int64\n",
      "Training report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.94      1.00      0.97      1648\n",
      "COMPARES_CONTRASTS       0.99      0.92      0.95       368\n",
      "         EXTENSION       0.99      0.88      0.93       171\n",
      "            FUTURE       1.00      0.94      0.97        62\n",
      "        MOTIVATION       0.99      0.92      0.95       276\n",
      "              USES       1.00      0.92      0.95       475\n",
      "\n",
      "          accuracy                           0.96      3000\n",
      "         macro avg       0.98      0.93      0.95      3000\n",
      "      weighted avg       0.96      0.96      0.96      3000\n",
      "\n",
      "Test report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.54      0.95      0.69       546\n",
      "COMPARES_CONTRASTS       0.13      0.02      0.04       121\n",
      "         EXTENSION       0.33      0.02      0.03        59\n",
      "            FUTURE       0.00      0.00      0.00        15\n",
      "        MOTIVATION       0.33      0.01      0.02       106\n",
      "              USES       0.25      0.03      0.06       153\n",
      "\n",
      "          accuracy                           0.53      1000\n",
      "         macro avg       0.27      0.17      0.14      1000\n",
      "      weighted avg       0.41      0.53      0.40      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\rf_purpose\\submission.csv\n",
      "Wall time: 596 ms\n",
      "Generated folder: submissions\\v2\\rf_influence\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "F:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output label dist\n",
      "INCIDENTAL     533\n",
      "INFLUENTIAL    467\n",
      "dtype: int64\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.97      0.99      0.98      1568\n",
      " INFLUENTIAL       0.98      0.97      0.97      1432\n",
      "\n",
      "    accuracy                           0.98      3000\n",
      "   macro avg       0.98      0.98      0.98      3000\n",
      "weighted avg       0.98      0.98      0.98      3000\n",
      "\n",
      "Test report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.51      0.59      0.55       457\n",
      " INFLUENTIAL       0.60      0.52      0.55       543\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.55      0.55      0.55      1000\n",
      "weighted avg       0.56      0.55      0.55      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\rf_influence\\submission.csv\n",
      "Wall time: 478 ms\n",
      "mlp-3 [<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, {'hidden_layer_sizes': (256, 256, 128)}]\n",
      "Generated folder: submissions\\v2\\mlp-3_purpose\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n",
      "Output label dist\n",
      "BACKGROUND            746\n",
      "USES                  139\n",
      "COMPARES_CONTRASTS     57\n",
      "EXTENSION              32\n",
      "MOTIVATION             24\n",
      "FUTURE                  2\n",
      "dtype: int64\n",
      "Training report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       1.00      1.00      1.00      1648\n",
      "COMPARES_CONTRASTS       0.99      1.00      1.00       368\n",
      "         EXTENSION       0.99      0.99      0.99       171\n",
      "            FUTURE       1.00      1.00      1.00        62\n",
      "        MOTIVATION       1.00      0.98      0.99       276\n",
      "              USES       1.00      1.00      1.00       475\n",
      "\n",
      "          accuracy                           1.00      3000\n",
      "         macro avg       1.00      0.99      0.99      3000\n",
      "      weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "Test report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.55      0.76      0.64       546\n",
      "COMPARES_CONTRASTS       0.32      0.15      0.20       121\n",
      "         EXTENSION       0.03      0.02      0.02        59\n",
      "            FUTURE       0.00      0.00      0.00        15\n",
      "        MOTIVATION       0.08      0.02      0.03       106\n",
      "              USES       0.23      0.21      0.22       153\n",
      "\n",
      "          accuracy                           0.47      1000\n",
      "         macro avg       0.20      0.19      0.19      1000\n",
      "      weighted avg       0.39      0.47      0.41      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\mlp-3_purpose\\submission.csv\n",
      "Wall time: 3min 1s\n",
      "Generated folder: submissions\\v2\\mlp-3_influence\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n",
      "Output label dist\n",
      "INCIDENTAL     519\n",
      "INFLUENTIAL    481\n",
      "dtype: int64\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.99      1.00      0.99      1568\n",
      " INFLUENTIAL       1.00      0.99      0.99      1432\n",
      "\n",
      "    accuracy                           0.99      3000\n",
      "   macro avg       0.99      0.99      0.99      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n",
      "Test report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.48      0.55      0.51       457\n",
      " INFLUENTIAL       0.57      0.50      0.54       543\n",
      "\n",
      "    accuracy                           0.52      1000\n",
      "   macro avg       0.53      0.53      0.52      1000\n",
      "weighted avg       0.53      0.52      0.52      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\mlp-3_influence\\submission.csv\n",
      "Wall time: 3min 39s\n",
      "mlp [<class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, {}]\n",
      "Generated folder: submissions\\v2\\mlp_purpose\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n",
      "Output label dist\n",
      "BACKGROUND            737\n",
      "USES                  130\n",
      "COMPARES_CONTRASTS     73\n",
      "MOTIVATION             35\n",
      "EXTENSION              22\n",
      "FUTURE                  3\n",
      "dtype: int64\n",
      "Training report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       1.00      1.00      1.00      1648\n",
      "COMPARES_CONTRASTS       0.99      1.00      1.00       368\n",
      "         EXTENSION       0.99      0.98      0.99       171\n",
      "            FUTURE       1.00      1.00      1.00        62\n",
      "        MOTIVATION       0.99      0.99      0.99       276\n",
      "              USES       1.00      1.00      1.00       475\n",
      "\n",
      "          accuracy                           1.00      3000\n",
      "         macro avg       1.00      0.99      1.00      3000\n",
      "      weighted avg       1.00      1.00      1.00      3000\n",
      "\n",
      "Test report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.56      0.75      0.64       546\n",
      "COMPARES_CONTRASTS       0.27      0.17      0.21       121\n",
      "         EXTENSION       0.09      0.03      0.05        59\n",
      "            FUTURE       0.00      0.00      0.00        15\n",
      "        MOTIVATION       0.06      0.02      0.03       106\n",
      "              USES       0.22      0.18      0.20       153\n",
      "\n",
      "          accuracy                           0.46      1000\n",
      "         macro avg       0.20      0.19      0.19      1000\n",
      "      weighted avg       0.38      0.46      0.41      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\mlp_purpose\\submission.csv\n",
      "Wall time: 2min 56s\n",
      "Generated folder: submissions\\v2\\mlp_influence\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n",
      "Output label dist\n",
      "INFLUENTIAL    533\n",
      "INCIDENTAL     467\n",
      "dtype: int64\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.99      0.99      0.99      1568\n",
      " INFLUENTIAL       0.99      0.99      0.99      1432\n",
      "\n",
      "    accuracy                           0.99      3000\n",
      "   macro avg       0.99      0.99      0.99      3000\n",
      "weighted avg       0.99      0.99      0.99      3000\n",
      "\n",
      "Test report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.48      0.49      0.49       457\n",
      " INFLUENTIAL       0.56      0.55      0.56       543\n",
      "\n",
      "    accuracy                           0.53      1000\n",
      "   macro avg       0.52      0.52      0.52      1000\n",
      "weighted avg       0.53      0.53      0.53      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\mlp_influence\\submission.csv\n",
      "Wall time: 2min 48s\n",
      "lr [<class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, {'n_jobs': -1}]\n",
      "Generated folder: submissions\\v2\\lr_purpose\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "F:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output label dist\n",
      "BACKGROUND    972\n",
      "USES           28\n",
      "dtype: int64\n",
      "Training report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.65      1.00      0.79      1648\n",
      "COMPARES_CONTRASTS       0.00      0.00      0.00       368\n",
      "         EXTENSION       0.00      0.00      0.00       171\n",
      "            FUTURE       0.00      0.00      0.00        62\n",
      "        MOTIVATION       0.00      0.00      0.00       276\n",
      "              USES       1.00      0.98      0.99       475\n",
      "\n",
      "          accuracy                           0.70      3000\n",
      "         macro avg       0.27      0.33      0.30      3000\n",
      "      weighted avg       0.52      0.70      0.59      3000\n",
      "\n",
      "Test report\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "        BACKGROUND       0.55      0.98      0.70       546\n",
      "COMPARES_CONTRASTS       0.00      0.00      0.00       121\n",
      "         EXTENSION       0.00      0.00      0.00        59\n",
      "            FUTURE       0.00      0.00      0.00        15\n",
      "        MOTIVATION       0.00      0.00      0.00       106\n",
      "              USES       0.36      0.07      0.11       153\n",
      "\n",
      "          accuracy                           0.54      1000\n",
      "         macro avg       0.15      0.17      0.14      1000\n",
      "      weighted avg       0.35      0.54      0.40      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\lr_purpose\\submission.csv\n",
      "Wall time: 8.29 s\n",
      "Generated folder: submissions\\v2\\lr_influence\n",
      "train: X=(3000, 13480), y=(3000,)\n",
      "test: X=(1000, 13480), y=(1000,)\n",
      "Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "F:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output label dist\n",
      "INCIDENTAL     577\n",
      "INFLUENTIAL    423\n",
      "dtype: int64\n",
      "Training report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.81      0.89      0.85      1568\n",
      " INFLUENTIAL       0.87      0.77      0.81      1432\n",
      "\n",
      "    accuracy                           0.83      3000\n",
      "   macro avg       0.84      0.83      0.83      3000\n",
      "weighted avg       0.83      0.83      0.83      3000\n",
      "\n",
      "Test report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  INCIDENTAL       0.51      0.64      0.57       457\n",
      " INFLUENTIAL       0.61      0.48      0.54       543\n",
      "\n",
      "    accuracy                           0.55      1000\n",
      "   macro avg       0.56      0.56      0.55      1000\n",
      "weighted avg       0.56      0.55      0.55      1000\n",
      "\n",
      "Writing submission file: submissions\\v2\\lr_influence\\submission.csv\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "reports = {}\n",
    "for model_key, model_params in model_configs.items():\n",
    "    model_cls, model_kwargs = model_params\n",
    "    to_dense=False\n",
    "    if model_cls in DENSE_MODELS:\n",
    "        to_dense=True\n",
    "    print(model_key, model_params)\n",
    "    for task in TASKS:\n",
    "        model = model_cls(**model_kwargs)\n",
    "        model, train_report, test_report = %time submission_pipeline(model, df, df_features, task, model_key=model_key, to_dense=to_dense)\n",
    "        reports[(model_key, task)] = {\"train\": train_report, \"test\": test_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = pd.concat([\n",
    "    pd.concat([\n",
    "        pd.DataFrame(report[split]).T.assign(model=model, task=task, split=split).reset_index().rename(columns={\"index\": \"label\"})\n",
    "        for split in report\n",
    "    ])\n",
    "    for (model, task), report in reports.items()\n",
    "], axis=0, sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>model</th>\n",
       "      <th>task</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.701620</td>\n",
       "      <td>0.998786</td>\n",
       "      <td>0.824236</td>\n",
       "      <td>1648.000</td>\n",
       "      <td>gbt</td>\n",
       "      <td>purpose</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>COMPARES_CONTRASTS</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.407609</td>\n",
       "      <td>0.578035</td>\n",
       "      <td>368.000</td>\n",
       "      <td>gbt</td>\n",
       "      <td>purpose</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>EXTENSION</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.669261</td>\n",
       "      <td>171.000</td>\n",
       "      <td>gbt</td>\n",
       "      <td>purpose</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>FUTURE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.991870</td>\n",
       "      <td>62.000</td>\n",
       "      <td>gbt</td>\n",
       "      <td>purpose</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>MOTIVATION</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.427536</td>\n",
       "      <td>0.598985</td>\n",
       "      <td>276.000</td>\n",
       "      <td>gbt</td>\n",
       "      <td>purpose</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>INCIDENTAL</td>\n",
       "      <td>0.507799</td>\n",
       "      <td>0.641138</td>\n",
       "      <td>0.566731</td>\n",
       "      <td>457.000</td>\n",
       "      <td>lr</td>\n",
       "      <td>influence</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>INFLUENTIAL</td>\n",
       "      <td>0.612293</td>\n",
       "      <td>0.476980</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>543.000</td>\n",
       "      <td>lr</td>\n",
       "      <td>influence</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>lr</td>\n",
       "      <td>influence</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.560046</td>\n",
       "      <td>0.559059</td>\n",
       "      <td>0.551482</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>lr</td>\n",
       "      <td>influence</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.564539</td>\n",
       "      <td>0.552000</td>\n",
       "      <td>0.550170</td>\n",
       "      <td>1000.000</td>\n",
       "      <td>lr</td>\n",
       "      <td>influence</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  label  precision    recall  f1-score   support model  \\\n",
       "0            BACKGROUND   0.701620  0.998786  0.824236  1648.000   gbt   \n",
       "1    COMPARES_CONTRASTS   0.993377  0.407609  0.578035   368.000   gbt   \n",
       "2             EXTENSION   1.000000  0.502924  0.669261   171.000   gbt   \n",
       "3                FUTURE   1.000000  0.983871  0.991870    62.000   gbt   \n",
       "4            MOTIVATION   1.000000  0.427536  0.598985   276.000   gbt   \n",
       "..                  ...        ...       ...       ...       ...   ...   \n",
       "135          INCIDENTAL   0.507799  0.641138  0.566731   457.000    lr   \n",
       "136         INFLUENTIAL   0.612293  0.476980  0.536232   543.000    lr   \n",
       "137            accuracy   0.552000  0.552000  0.552000     0.552    lr   \n",
       "138           macro avg   0.560046  0.559059  0.551482  1000.000    lr   \n",
       "139        weighted avg   0.564539  0.552000  0.550170  1000.000    lr   \n",
       "\n",
       "          task  split  \n",
       "0      purpose  train  \n",
       "1      purpose  train  \n",
       "2      purpose  train  \n",
       "3      purpose  train  \n",
       "4      purpose  train  \n",
       "..         ...    ...  \n",
       "135  influence   test  \n",
       "136  influence   test  \n",
       "137  influence   test  \n",
       "138  influence   test  \n",
       "139  influence   test  \n",
       "\n",
       "[140 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th colspan=\"2\" halign=\"left\">influence</th>\n",
       "      <th colspan=\"2\" halign=\"left\">purpose</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gbt</td>\n",
       "      <td>0.534654</td>\n",
       "      <td>0.769850</td>\n",
       "      <td>0.151085</td>\n",
       "      <td>0.719327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lr</td>\n",
       "      <td>0.551482</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.135456</td>\n",
       "      <td>0.295864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp</td>\n",
       "      <td>0.523246</td>\n",
       "      <td>0.991648</td>\n",
       "      <td>0.186824</td>\n",
       "      <td>0.995218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp-3</td>\n",
       "      <td>0.523726</td>\n",
       "      <td>0.993987</td>\n",
       "      <td>0.185840</td>\n",
       "      <td>0.994995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>0.549955</td>\n",
       "      <td>0.975595</td>\n",
       "      <td>0.140355</td>\n",
       "      <td>0.954409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "task  influence             purpose          \n",
       "split      test     train      test     train\n",
       "model                                        \n",
       "gbt    0.534654  0.769850  0.151085  0.719327\n",
       "lr     0.551482  0.829630  0.135456  0.295864\n",
       "mlp    0.523246  0.991648  0.186824  0.995218\n",
       "mlp-3  0.523726  0.993987  0.185840  0.994995\n",
       "rf     0.549955  0.975595  0.140355  0.954409"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reports.loc[\n",
    "    df_reports.label==\"macro avg\", \n",
    "    [\"f1-score\", \"model\", \"task\", \"split\"]\n",
    "].pivot_table(index=\"model\", columns=[\"task\", \"split\"], values=\"f1-score\", aggfunc=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "split &   test &  train \\\\\n",
      "model &        &        \\\\\n",
      "\\midrule\n",
      "lr    &  0.135 &  0.296 \\\\\n",
      "rf    &  0.140 &  0.954 \\\\\n",
      "gbt   &  0.151 &  0.719 \\\\\n",
      "mlp-3 &  0.186 &  0.995 \\\\\n",
      "mlp   &  0.187 &  0.995 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>lr</td>\n",
       "      <td>0.135456</td>\n",
       "      <td>0.295864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>0.140355</td>\n",
       "      <td>0.954409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gbt</td>\n",
       "      <td>0.151085</td>\n",
       "      <td>0.719327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp-3</td>\n",
       "      <td>0.185840</td>\n",
       "      <td>0.994995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp</td>\n",
       "      <td>0.186824</td>\n",
       "      <td>0.995218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split      test     train\n",
       "model                    \n",
       "lr     0.135456  0.295864\n",
       "rf     0.140355  0.954409\n",
       "gbt    0.151085  0.719327\n",
       "mlp-3  0.185840  0.994995\n",
       "mlp    0.186824  0.995218"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = df_reports.loc[\n",
    "    (df_reports.label==\"macro avg\") & (df_reports.task==\"purpose\"), \n",
    "    [\"f1-score\", \"model\", \"task\", \"split\"]\n",
    "].pivot_table(index=\"model\", columns=\"split\", values=\"f1-score\", aggfunc=\"first\").sort_values(\"test\")\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    print(df_t.to_latex())\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "split &   test &  train \\\\\n",
      "model &        &        \\\\\n",
      "\\midrule\n",
      "mlp   &  0.523 &  0.992 \\\\\n",
      "mlp-3 &  0.524 &  0.994 \\\\\n",
      "gbt   &  0.535 &  0.770 \\\\\n",
      "rf    &  0.550 &  0.976 \\\\\n",
      "lr    &  0.551 &  0.830 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>split</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mlp</td>\n",
       "      <td>0.523246</td>\n",
       "      <td>0.991648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp-3</td>\n",
       "      <td>0.523726</td>\n",
       "      <td>0.993987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gbt</td>\n",
       "      <td>0.534654</td>\n",
       "      <td>0.769850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>0.549955</td>\n",
       "      <td>0.975595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lr</td>\n",
       "      <td>0.551482</td>\n",
       "      <td>0.829630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "split      test     train\n",
       "model                    \n",
       "mlp    0.523246  0.991648\n",
       "mlp-3  0.523726  0.993987\n",
       "gbt    0.534654  0.769850\n",
       "rf     0.549955  0.975595\n",
       "lr     0.551482  0.829630"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = df_reports.loc[\n",
    "    (df_reports.label==\"macro avg\") & (df_reports.task==\"influence\"), \n",
    "    [\"f1-score\", \"model\", \"task\", \"split\"]\n",
    "].pivot_table(index=\"model\", columns=\"split\", values=\"f1-score\", aggfunc=\"first\").sort_values(\"test\")\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    print(df_t.to_latex())\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "label &  BACKGROUND &  COMPARES\\_CONTRASTS &  EXTENSION &  FUTURE &  MOTIVATION &   USES &  accuracy &  macro avg &  weighted avg \\\\\n",
      "model &             &                     &            &         &             &        &           &            &               \\\\\n",
      "\\midrule\n",
      "lr    &       0.702 &               0.000 &      0.000 &     0.0 &       0.000 &  0.110 &     0.543 &      0.135 &         0.400 \\\\\n",
      "rf    &       0.692 &               0.042 &      0.032 &     0.0 &       0.018 &  0.058 &     0.528 &      0.140 &         0.396 \\\\\n",
      "gbt   &       0.683 &               0.057 &      0.056 &     0.0 &       0.000 &  0.110 &     0.518 &      0.151 &         0.400 \\\\\n",
      "mlp-3 &       0.641 &               0.202 &      0.022 &     0.0 &       0.031 &  0.219 &     0.467 &      0.186 &         0.412 \\\\\n",
      "mlp   &       0.639 &               0.206 &      0.049 &     0.0 &       0.028 &  0.198 &     0.462 &      0.187 &         0.410 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>COMPARES_CONTRASTS</th>\n",
       "      <th>EXTENSION</th>\n",
       "      <th>FUTURE</th>\n",
       "      <th>MOTIVATION</th>\n",
       "      <th>USES</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>lr</td>\n",
       "      <td>0.702240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.135456</td>\n",
       "      <td>0.400329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>0.692051</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018349</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.140355</td>\n",
       "      <td>0.395593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gbt</td>\n",
       "      <td>0.682529</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110497</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.151085</td>\n",
       "      <td>0.399805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp-3</td>\n",
       "      <td>0.640867</td>\n",
       "      <td>0.202247</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.185840</td>\n",
       "      <td>0.412478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp</td>\n",
       "      <td>0.639127</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028369</td>\n",
       "      <td>0.197880</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.186824</td>\n",
       "      <td>0.410108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label  BACKGROUND  COMPARES_CONTRASTS  EXTENSION  FUTURE  MOTIVATION  \\\n",
       "model                                                                  \n",
       "lr       0.702240            0.000000   0.000000     0.0    0.000000   \n",
       "rf       0.692051            0.041667   0.032258     0.0    0.018349   \n",
       "gbt      0.682529            0.057143   0.056338     0.0    0.000000   \n",
       "mlp-3    0.640867            0.202247   0.021978     0.0    0.030769   \n",
       "mlp      0.639127            0.206186   0.049383     0.0    0.028369   \n",
       "\n",
       "label      USES  accuracy  macro avg  weighted avg  \n",
       "model                                               \n",
       "lr     0.110497     0.543   0.135456      0.400329  \n",
       "rf     0.057803     0.528   0.140355      0.395593  \n",
       "gbt    0.110497     0.518   0.151085      0.399805  \n",
       "mlp-3  0.219178     0.467   0.185840      0.412478  \n",
       "mlp    0.197880     0.462   0.186824      0.410108  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = df_reports.loc[\n",
    "    (df_reports.split==\"test\") & (df_reports.task==\"purpose\"), \n",
    "    [\"label\", \"f1-score\", \"model\",]\n",
    "].pivot_table(index=\"model\", columns=\"label\", values=\"f1-score\", aggfunc=\"first\").sort_values(\"macro avg\")\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    print(df_t.to_latex())\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "label &  INCIDENTAL &  INFLUENTIAL &  accuracy &  macro avg &  weighted avg \\\\\n",
      "model &             &              &           &            &               \\\\\n",
      "\\midrule\n",
      "mlp   &       0.487 &        0.559 &     0.526 &      0.523 &         0.526 \\\\\n",
      "mlp-3 &       0.512 &        0.535 &     0.524 &      0.524 &         0.525 \\\\\n",
      "gbt   &       0.568 &        0.502 &     0.537 &      0.535 &         0.532 \\\\\n",
      "rf    &       0.545 &        0.554 &     0.550 &      0.550 &         0.550 \\\\\n",
      "lr    &       0.567 &        0.536 &     0.552 &      0.551 &         0.550 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>INCIDENTAL</th>\n",
       "      <th>INFLUENTIAL</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mlp</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>0.559480</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.523246</td>\n",
       "      <td>0.526362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp-3</td>\n",
       "      <td>0.512295</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.523726</td>\n",
       "      <td>0.524709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gbt</td>\n",
       "      <td>0.567694</td>\n",
       "      <td>0.501615</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.534654</td>\n",
       "      <td>0.531813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.549955</td>\n",
       "      <td>0.550342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lr</td>\n",
       "      <td>0.566731</td>\n",
       "      <td>0.536232</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.551482</td>\n",
       "      <td>0.550170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label  INCIDENTAL  INFLUENTIAL  accuracy  macro avg  weighted avg\n",
       "model                                                            \n",
       "mlp      0.487013     0.559480     0.526   0.523246      0.526362\n",
       "mlp-3    0.512295     0.535156     0.524   0.523726      0.524709\n",
       "gbt      0.567694     0.501615     0.537   0.534654      0.531813\n",
       "rf       0.545455     0.554455     0.550   0.549955      0.550342\n",
       "lr       0.566731     0.536232     0.552   0.551482      0.550170"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = df_reports.loc[\n",
    "    (df_reports.split==\"test\") & (df_reports.task==\"influence\"), \n",
    "    [\"label\", \"f1-score\", \"model\",]\n",
    "].pivot_table(index=\"model\", columns=\"label\", values=\"f1-score\", aggfunc=\"first\").sort_values(\"macro avg\")\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    print(df_t.to_latex())\n",
    "df_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = SUBMISSION_PATH / \"lr_influence/model.joblib\"\n",
    "lr_influence_model = load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 13480)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_influence_model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_influence_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['citation_context_tfidf', '00__0']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"citation_context_tfidf__00__0\".split(\"__\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>-0.016262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000</td>\n",
       "      <td>-0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>001</td>\n",
       "      <td>0.045382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>026</td>\n",
       "      <td>-0.060330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>04</td>\n",
       "      <td>-0.069719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature    weight\n",
       "0      00 -0.016262\n",
       "1     000 -0.004043\n",
       "2     001  0.045382\n",
       "3     026 -0.060330\n",
       "4      04 -0.069719"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coefs = pd.DataFrame(\n",
    "    lr_influence_model.coef_.T, \n",
    "    index=[x.split(\"__\", 1)[-1] for x in ct.get_feature_names()], \n",
    "    columns=[\"weight\"]\n",
    ").rename_axis(\"feature\").reset_index()\n",
    "df_coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrlr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{INCIDENTAL} & \\multicolumn{2}{l}{INFLUENTIAL} \\\\\n",
      "{} &    feature & weight &      feature & weight \\\\\n",
      "\\midrule\n",
      "0 &  including & -0.703 &          the &  1.547 \\\\\n",
      "1 &   learning & -0.702 &        first &  0.813 \\\\\n",
      "2 &         11 & -0.652 &         were &  0.742 \\\\\n",
      "3 &       2002 & -0.629 &           to &  0.676 \\\\\n",
      "4 &        and & -0.624 &           of &  0.631 \\\\\n",
      "5 &        amp & -0.623 &    cessation &  0.620 \\\\\n",
      "6 &   academic & -0.608 &           us &  0.575 \\\\\n",
      "7 &     impact & -0.580 &          avh &  0.518 \\\\\n",
      "8 &         13 & -0.544 &        virus &  0.513 \\\\\n",
      "9 &   research & -0.495 &  temperature &  0.510 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">INCIDENTAL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">INFLUENTIAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>including</td>\n",
       "      <td>-0.703429</td>\n",
       "      <td>the</td>\n",
       "      <td>1.546984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>learning</td>\n",
       "      <td>-0.702319</td>\n",
       "      <td>first</td>\n",
       "      <td>0.812547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.652398</td>\n",
       "      <td>were</td>\n",
       "      <td>0.742135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2002</td>\n",
       "      <td>-0.629222</td>\n",
       "      <td>to</td>\n",
       "      <td>0.675671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>and</td>\n",
       "      <td>-0.624020</td>\n",
       "      <td>of</td>\n",
       "      <td>0.631087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>amp</td>\n",
       "      <td>-0.622686</td>\n",
       "      <td>cessation</td>\n",
       "      <td>0.619857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>academic</td>\n",
       "      <td>-0.608006</td>\n",
       "      <td>us</td>\n",
       "      <td>0.574899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>impact</td>\n",
       "      <td>-0.580294</td>\n",
       "      <td>avh</td>\n",
       "      <td>0.517897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.544389</td>\n",
       "      <td>virus</td>\n",
       "      <td>0.512790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>research</td>\n",
       "      <td>-0.495197</td>\n",
       "      <td>temperature</td>\n",
       "      <td>0.509712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  INCIDENTAL            INFLUENTIAL          \n",
       "     feature    weight      feature    weight\n",
       "0  including -0.703429          the  1.546984\n",
       "1   learning -0.702319        first  0.812547\n",
       "2         11 -0.652398         were  0.742135\n",
       "3       2002 -0.629222           to  0.675671\n",
       "4        and -0.624020           of  0.631087\n",
       "5        amp -0.622686    cessation  0.619857\n",
       "6   academic -0.608006           us  0.574899\n",
       "7     impact -0.580294          avh  0.517897\n",
       "8         13 -0.544389        virus  0.512790\n",
       "9   research -0.495197  temperature  0.509712"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t = pd.concat({\n",
    "    INFLUENCE_LABELS[0]: df_coefs.sort_values(\"weight\").reset_index(drop=True),\n",
    "    INFLUENCE_LABELS[1]: df_coefs.sort_values(\"weight\", ascending=False).reset_index(drop=True),\n",
    "}, axis=1, sort=False).head(10)\n",
    "\n",
    "with pd.option_context(\"precision\", 3):\n",
    "    print(df_t.to_latex())\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}